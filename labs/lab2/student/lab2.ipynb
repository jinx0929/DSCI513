{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dsci513_header2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 2: Grouping, joins, and table manipulation\n",
    "\n",
    "**Arman Seyed-Ahmadi, November 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "---\n",
    "rubric={mechanics:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)\n",
    "- Make sure to upload a PDF version of your lab notebook to Gradescope, in addition to the `.ipynb` file. Use the `Webpdf` option of Jupyter Lab if `PDF` doesn't work.\n",
    "- Add a link to your GitHub repository here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configurations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql\n",
    "%config SqlMagic.displaylimit = 30\n",
    "%config SqlMagic.autolimit = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "with open('data/credentials.json') as f:\n",
    "    login = json.load(f)\n",
    "    \n",
    "username = login['user']\n",
    "password = urllib.parse.quote(login['password'])\n",
    "host = login['host']\n",
    "port = login['port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1: Aggregations and grouping\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, use the `pd.read_sql_query` function from Pandas to execute your queries. But we need to use the `psycopg2` package to establish a connection to the `world_dsci513` database first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='world_dsci513', **login)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we read query results into Pandas dataframes, you'll see an **index column** appearing in your results. That is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to answer the following question:\n",
    "\n",
    "How much higher is the population of the most populated country in the world, with respect to the average population of all countries in the world, expressed in percent?\n",
    "\n",
    "- You can find this value using the the formula $(\\text{pop} - \\text{pop}_\\text{avg}) / \\text{pop}_\\text{avg}) \\times 100$.\n",
    "- Your query should print the value with only one digit after the decimal point, followed by the percent sign `%`, e.g. `2500.0%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to answer the following question:\n",
    "\n",
    "What is the maximum, average, and minimum population density (population per surface area [person / km$^2$]) of countries located in Europe?\n",
    "\n",
    "- The values in the `surfacearea` column already have the required unit (km$^2$); no unit conversion is required.\n",
    "- Your column headers should read _Max pop_density_, _Average pop_density_, and _Min pop_density_.\n",
    "- Round all values to 2 decimal digits.\n",
    "\n",
    ">**Note:** Remember that you have to convert approximate types (e.g. double precision or real) to `NUMERIC` to be able to use the `ROUND()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "\n",
    "rubric={reasoning:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to write a query to return the name of the country with the greatest surface area in the `world_dsci513` database. Would the following query work as expected? Explain your answer in a 2-3 sentences.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    name, MAX(surfacearea)\n",
    "FROM\n",
    "    country\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer goes here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 (OPTIONAL)\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you write a query to answer the question posed in [Exercise 1.3](#1.3)? Your result should contain one column and one row containing the value described above.\n",
    "\n",
    "> **Hint:** Surprisingly, you don't need to use aggregation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that returns the total population of each region of the world according to the `country` table.\n",
    "\n",
    "- Sort your results in descending order by each region's total population (Hint: Be careful not to sort alphabetically!).\n",
    "- In order to increase the readability of the results, use the `to_char()` function to separate groups of thousands with commas\n",
    "(see the documentation [here](https://www.postgresql.org/docs/current/functions-formatting.html#FUNCTIONS-FORMATTING-NUMERIC-TABLE)).\n",
    "For example, to accommodate numbers going up to a billion, you can use `to_char(column, '9,999,999,999')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the number of countries in each region that have a republic form of government? Sort your results by the number of countries in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 (OPTIONAL)\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `countrylanguage` table, write a query to find the `countrycode` and number of spoken languages in countries where \n",
    "\n",
    "- Each listed language is spoken by at least 10% of the population,\n",
    "- There are at least 2 spoken languages in those countries.\n",
    "\n",
    "Sort the resulting rows by the number of listed languages in each country in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to find the `countrycode` of countries that have at least 3 official languages. To verify your results, also return the number of official languages and name the corresponding column `num_official_lang`. Sort the returned rows according to this column in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 2: Why don't you `JOIN` us?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to figure out which countries we're talking about in Exercise [1.8](#1.8) just by looking at their codes. Copy the query you wrote in Exercise [1.8](#1.8) here, and modify it such that it returns the name of each country instead of country code.\n",
    "\n",
    ">**Hint:** You need to join the `country` and `countrylanguage` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that finds the ratio of the population of each country's capital city to its entire population shown as a percentage value, for countries that have a population of at least 1,000,000.\n",
    "\n",
    "- Your query should list the country name, capital city, and the population ratio percentage value\n",
    "- Name the population ratio column `pop_ratio`, and round the values to 1 decimal digit\n",
    "- Sort your results in descending order by the population percentage\n",
    "- Limit the number of returned countries to 20 in your SQL query\n",
    "\n",
    "> **Hint:** Watch out for integer division; use type conversion if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that lists country names along with the average population and number of their listed cities.\n",
    "\n",
    "- Pick appropriate names for the columns in your results. They can be anything you like.\n",
    "- Use `to_char()` (which you've learned in a previous exercise in this lab) to format the average populations such that groups of thousands are separated by commas, and decimal digits are eliminated. For example, 1656782.25 should be shown as 1,656,782.\n",
    "- Sort the results by the number of cities in each country in descending order\n",
    "- limit the number of returned rows to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 (OPTIONAL)\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that returns country names along with their region and population. Your query should also return\n",
    "\n",
    "- the number of official languages in each country\n",
    "- the number of cities of each country having a population of over 1 million\n",
    "\n",
    "Make sure that\n",
    "\n",
    "- Give appropriate names to the additional columns\n",
    "- Sort your results in descending order by the number of official languages in each country\n",
    "\n",
    "> **Hint:** Since you need to do 3 joins, you'll get a lot of duplicates. Make sure to count only unique values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5\n",
    "\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've learned about grouping, aggregation and joins, let's revisit the last problem of Lab 1 and try to arrive at the same result using pure SQL. I hope after writing this query entirely in SQL, you'll appreciate the convenience of extracting this kind of information, compared to how you've done it in Pandas!\n",
    "\n",
    "So without further ado, let's write a query that answers this question: what are the 10 most (natively) spoken languages in the world?\n",
    "\n",
    "- Each row should show the language and the respective speaker population\n",
    "- Sort your results by the second column in descending order\n",
    "- Format the population numbers such that groups of thousands are separated with commas (you've already learned how to do this in previous exercises of this lab)\n",
    "- Use appropriate column aliases that you like\n",
    "\n",
    "Verify that you get exactly the same result as that you've arrived at in Lab 1 using Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 3: More joins with the IMDB database\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll explore the `imdb_dsci513` database more in depth and extract richer information by pulling data from various tables and joining them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='imdb_dsci513', **login)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that returns the names of all actors/actresses of the movie \"Catch Me If You Can\".\n",
    "\n",
    "> **Hint:** The data you need for this exercise is spread across the `movies`, `acting_roles`, and `names` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that lists each movie genre along with the average runtime of movies belonging to each genre. Sort your results in descending order by the latter column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to find the number of \"drama\" and \"biography\" movies in which \"Marlon Brando\", \"Gary Oldman\", and \"Robin Williams\" played a role. Your query should list each actor's name, genre, and number of movies played by that actor in that genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 4: Unter is the new Uber\n",
    "---\n",
    "\n",
    "In this exercise, we're going to create a database called `unter` and its tables from scratch, and then populate its tables with some fake data in the later exercises. The database `unter` is supposed to store data of employees, drivers, cars, etc. of a company which provides taxi services. Let's call our company _Unter_, because we want to be a rival to Uber!\n",
    "\n",
    "(Uber in German means \"over\" or \"above\", so I've chosen \"Unter\" meaning \"under\" or \"below\" to oppose and compete with them even in name. But it's kinda obvious where the company's fate is headed with this name choice 😄)\n",
    "\n",
    "\n",
    "**Please do this exercise on your local installation of Postgres, NOT on the remote server!**\n",
    "\n",
    "Because you might want to drop your database several times as you try out new things that you've learned and you probably want to start fresh each time, I thought it may not be convenient to do it every time using the pgAdmin GUI. So I've given you the following cell to be able to **drop your database `unter` forcefully** (regardless if there are connections to it or not), and re-create it immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='postgres', **login)\n",
    "\n",
    "autocommit = psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT\n",
    "conn.set_isolation_level(autocommit)\n",
    "conn.cursor().execute(\"DROP DATABASE IF EXISTS unter WITH (FORCE);\")\n",
    "conn.cursor().execute(\"CREATE DATABASE unter;\")\n",
    "conn.cursor().close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you can use pgAdmin to see that your new database `unter` is created. Don't forget to right-click your \"Databases\" group in the browser pane and click \"Refresh\". Alternatively, you can use the following cell to see if the database `unter` appears in the list of databases on your Postgres server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='postgres', **login)\n",
    "\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT datname FROM pg_database;\")\n",
    "    print([i[0] for i in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1\n",
    "\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've created the database, it's time to create the tables we need. I've included `employee.csv` in the `data` folder of this assignment, which contains the data of employees of our company. Given this CSV file, your task is:\n",
    "\n",
    "- Create a new table and call it `employee`\n",
    "- Create an auto-incrementing column called `id` (Hint: Remember the `SERIAL` data type?). This is the primary-key column.\n",
    "- Create other columns in your table that correspond to the columns you see in `employee.csv`. Use the same column names as in the CSV file.\n",
    "- You also need to specify data types for your columns. To do this, inspect `employee.csv` and choose the most appropriate data types according to the values you see.\n",
    "- Except for `exit_date`, none of the columns can be `NULL`.\n",
    "- Values in column `sin` should be unique.\n",
    "- The number of digits stored in column `sin` should be exactly 9 (Hint: Use the `CHECK` keyword together with `LENGTH()`).\n",
    "\n",
    "> **Note:** Use your best judgment to choose the number of characters to allow in, for example, `VARCHAR(n)`. Just make sure that it's not unreasonably short or long. In any other case, it's arbitrary and up to you what length you use.\n",
    "\n",
    "Make sure to enforce the constraints in your table. I've provided starter Python code for using the `psycopg2` package to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='unter', **login)\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        ...\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating your table, run `\\d employee` in `psql` to see if your **columns** and **constraints** are properly created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to create things feels powerful, so let's create more!\n",
    "\n",
    "Now let's create a table `driver` for the drivers who work at Unter. I've provided a data file called `driver.csv` in the `data` folder of this assignment. If you inspect this file, you'll see that the data about our drivers is pretty much similar to our employees data. The only difference is that in `driver.csv` we also store driver's license information, in addition to other columns in the `employee` table.\n",
    "\n",
    "- You can use the same commands that you've written to create the `employee` table, but make sure to add more columns to accommodate the data in `driver.csv`.\n",
    "- None of the new columns can be null.\n",
    "- Add a constraint to the `driver_license` column so that its values are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='unter', **login)\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        ...\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3 (OPTIONAL)\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the `driver` table, we decide to add the following constraints in order to avoid having incorrect values inserted into the table..\n",
    "\n",
    "- The date stored in `issue_date` can't be later than the date on which a row is inserted\n",
    "- The date stored in `expiry_date` column can't be earlier than the `issue_date`\n",
    "\n",
    "Use the `ALTER` command and the following cell to add the above constraints to the `driver` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='unter', **login)\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        ...\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.4\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, almost there. We need to create two more tables, `car_model` and `cab`. `car_model` stores information about each type of car, whereas `cab` contains data about the particular cabs that the drivers of our company own. \n",
    "\n",
    "This time I've given you part of the `CREATE TABLE` statements for both tables, and you're in charge of adding constraints.\n",
    "\n",
    "**`car_model` table:**\n",
    "\n",
    "- Add the primary key constraint in the table creation statement\n",
    "\n",
    "**`cab` table:**\n",
    "\n",
    "- Add the primary key constraint in the table creation statement\n",
    "- Each cab is a particular type of car, the information of which can be found in the `car_model` table. In order to ensure that each cab in the `cab` table can only be of the car types in the `car_model` table, the `car_model_id` column in the `cab` table should reference the `id` column of the `car_model` table. Add a constraint that enforces this.\n",
    "- The owner of each can in the `cab` table should be one of the drivers of our company. Add a constraint to the `cab` table such that `owner_id` references the `id` column of the `driver` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='unter', **login)\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE car_model(\n",
    "        id SERIAL,\n",
    "        model_name VARCHAR(64) NOT NULL,\n",
    "        miles_per_gallon REAL,\n",
    "        year DATE,\n",
    "        origin VARCHAR(32),\n",
    "        \n",
    "        ...\n",
    "    );\n",
    "\n",
    "    CREATE TABLE cab(\n",
    "        id SERIAL,\n",
    "        licence_plate VARCHAR(32) UNIQUE NOT NULL,\n",
    "        car_model_id INT,\n",
    "        owner_id INT,\n",
    "        active BOOLEAN NOT NULL,\n",
    "\n",
    "        ...\n",
    "    );\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 5: Sanitize your SQL too, not just your hands\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Some evil people have gotten really unhappy with the progress we've made with our amazing taxi company \"Unter\", so they hire a hacker to attack our company's database. Suppose that we have a website where our employees can log in and access their information. In order to give access, we have a table called `user` that stores employees/clients username and passwords. So when a user tries to log in, we do the authentication and retrieve that user's information using the following query\n",
    "\n",
    "```python\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(f\"SELECT * FROM users WHERE username = '{emp_user}' AND password = '{emp_passwd}';\")\n",
    "```\n",
    "\n",
    "Embedding strings directly in a SQL query using\n",
    "\n",
    "- Python's f-strings (e.g. `f\"I have {variable} apples\"`) or\n",
    "- Python's string concatenation (e.g. `\"I have \"+ variable + \" apples\"`)\n",
    "\n",
    "is **EXTREMELY DANGEROUS, and must always be avoided!**. It makes your application/service vulnerable to a particular security breach called [**SQL injection attacks**](https://en.wikipedia.org/wiki/SQL_injection).\n",
    "\n",
    "See what `psycopg2` documentation says about this:\n",
    "<img src=\"img/warning.png\" width=\"800\">\n",
    "\n",
    "But why? I'll show you!\n",
    "\n",
    "With the above embedding of variables directly into the string that we send to the database server, a hacker who is well-seasoned in SQL can carefully craft a username or password string like this:\n",
    "\n",
    "```python\n",
    "emp_user = \"' OR 1 = 1; SELECT * FROM user; --\"\n",
    "```\n",
    "\n",
    "Now, what your database receives as a query is this:\n",
    "\n",
    "```sql\n",
    "SELECT * FROM users WHERE username = '' OR 1 = 1; SELECT * FROM user; -- ' AND password = '{emp_passwd}';\")\n",
    "```\n",
    "\n",
    "Since `OR 1 = 1` is always true, the `WHERE` condition is short-circuited, and `SELECT * FROM user;` will get executed, while the rest of the query is neglected because of the `--`! Now the hacker has access to the username and passwords of all users stored in the `user` tables.\n",
    "\n",
    "**How to avoid SQL injection attack?**\n",
    "\n",
    "There are a few ways we can make sure that our application/service is not vulnerable to SQL injection attacks, one of which is to use **parameterized statements**. In `psycopg2`, you can safely embed variables inside your SQL statements using `%s` as parameter placeholders, and the second argument of the `.execute()` method to pass the parameters securely to the query ([see here for details](https://www.psycopg.org/docs/usage.html#passing-parameters-to-sql-queries)). For example, we can safely write our original query as:\n",
    "\n",
    "```python\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(f\"SELECT * FROM users WHERE username = %s AND password = %s;\",\n",
    "               (emp_user, emp_passwd))\n",
    "```\n",
    "\n",
    "The above SQL statement is now a **sanitized** query, and can be safely executed. In this manner, the query and data are sent to the server separately. By the time data arrives, the database server already knows what the query exactly is. This means that the query cannot be changed no matter what the passed data is.\n",
    "\n",
    "Furthermore, the parameters are checked before being used in the SQL statement by using `%` placeholders. For example, a single quote `'` in a parameter never gets a chance to close another single quote in the query, because it will be replaced with `''` and will therefore be escaped!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you're in charge of assessing the security of the `unter` database, and you want to test to see if you can actually break the database on purpose by injecting a SQL statement. I've defined a sample row for you in the cell below, and also a VERY DANGEROUS and naively formed SQL statement ☠️ (you should never write a SQL query in Python like this!).\n",
    "\n",
    "Your task is to try and modify the value of one of the columns such that when the SQL statement is formed and executed, it deletes the `driver` table!\n",
    "\n",
    "**Hint:** It's easier to use the last column for your SQL injection.\n",
    "\n",
    "**Hint:** Remember that other tables depend on the `driver` table, so unless you address this properly in your SQL statement, you won't be able to delete the table.\n",
    "\n",
    "**Hint:** Don't forget to use double quotes for your value so that the single quotes in the Python code do not interfere with your SQL strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Bartel', 'Dall', '1997-08-15',\n",
    "       '102-380-7032', '86 Vermont Park', 'G5T 7X1',\n",
    "       'North Vancouver', '2018-06-05', '2020-02-01',\n",
    "       '200887794', '100-86-4796', '2019-05-05', '2024-05-05']\n",
    "\n",
    "(first_name, last_name, birth_date, phone, home_address,\n",
    " home_postal, home_city, hire_date, exit_date, sin,\n",
    " driver_licence, issue_date, expiry_date) = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready? Let's go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(f\"\"\"\n",
    "        INSERT INTO driver VALUES\n",
    "            (DEFAULT,\n",
    "            '{first_name}', '{last_name}', '{birth_date}', '{phone}', '{home_address}',\n",
    "            '{home_postal}', '{home_city}', '{hire_date}', '{exit_date}', '{sin}',\n",
    "            '{driver_licence}', '{issue_date}', '{expiry_date}');\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is recipe for disaster 😵‍💫\n",
    "\n",
    "To make sure that the `driver` table is actually deleted as a result of your SQL injection, run the following cell to list tables in your `unter` database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\"\"\")\n",
    "    print([i[0] for i in cur.fetchall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I hope you agree with me now how dangerous it is to expose your database like this. Always sanitize your queries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2\n",
    "\n",
    "rubric={accuracy:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've learned how to avoid the risk of embedding strings directly in your SQL statement, let's practice populating your `employee` table from within Python properly and safely in this exercise using the data in `employee.csv` file.\n",
    "\n",
    "In order to form safe SQL statements in Python, you need to use `psycopg2`s placeholders `%` for embedding parameters in your SQL statements, instead of using f-strings or string concatenation (see [here](https://www.psycopg.org/docs/usage.html#passing-parameters-to-sql-queries)) for details.\n",
    "\n",
    "I've provided some starter code for you that reads the `employee.csv` line by line and stores the column values in intermediate variables. You can use those variables to form your `INSERT` statements inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn, conn.cursor() as cur:\n",
    "    \n",
    "    with open('data/employee.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        next(reader)  # skip the header row\n",
    "\n",
    "        for row in reader:\n",
    "            \n",
    "            (first_name, last_name, birth_date, phone,\n",
    "             home_address, home_postal, home_city,\n",
    "             hire_date, exit_date, sin) = row\n",
    "            \n",
    "            if exit_date == '': exit_date = None\n",
    "            \n",
    "            cur.execute(\n",
    "                ...\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the table `employee` is populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM employee LIMIT 5;\", con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 (OPTIONAL)\n",
    "\n",
    "rubric={accuracy:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you've learned how to create sanitized and safe SQL `INSERT` statements to read data from external files and load them into your database using `psycopg2` in Python. Let's now practice how to import data into the tables of your database using the `\\copy` meta-command in Postgres that you can run from `psql`.\n",
    "\n",
    "Your taks is to use the the `\\copy` meta-command to import the data stored in the `car_model.csv` file in the `data` folder of this assignment into your `car_model` table. Here is a [link](https://www.postgresql.org/docs/10/app-psql.html#APP-PSQL-META-COMMANDS-COPY) to Postgres documentation for the `\\copy` command. Feel free to look up the internet to see how you can form the appropriate `\\copy` command for this exercise.\n",
    "\n",
    "**Hint:** In `psql`, first navigate to the directory where your Lab 2 files are located before trying your command.\n",
    "\n",
    "**Hint:** If your `\\copy` command is successfully run, you'll see `COPY 406` in the output of `psql`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "Your answer goes here.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the data is properly imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM car_model LIMIT 10;\", con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 But it's no joke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reward for completing Exercise 5, here is a cartoon that only SQL people understand:\n",
    "\n",
    "<img src=\"img/cartoon.png\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  },
  "kernelspec": {
   "display_name": "Python [conda env:dsci513env]",
   "language": "python",
   "name": "conda-env-dsci513env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lecture Outline",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
